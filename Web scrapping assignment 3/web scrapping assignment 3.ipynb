{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60625b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in ./opt/anaconda3/lib/python3.9/site-packages (4.11.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (2022.9.24)\n",
      "Requirement already satisfied: trio~=0.17 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: outcome in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=20.1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sniffio in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.1.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in ./opt/anaconda3/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in ./opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in ./opt/anaconda3/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ec9122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product to search for: guitar\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_element_by_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l_/s9krkn1s6jlgwn8tl_ywpb300000gn/T/ipykernel_80052/4187408103.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the product to search for: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0msearch_amazon_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/l_/s9krkn1s6jlgwn8tl_ywpb300000gn/T/ipykernel_80052/4187408103.py\u001b[0m in \u001b[0;36msearch_amazon_product\u001b[0;34m(product_name)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Find the search box element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0msearch_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"twotabsearchtextbox\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Input the product name and press Enter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_element_by_id'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "def search_amazon_product(product_name):\n",
    "    # Set up the WebDriver (assuming you have ChromeDriver installed)\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    # Navigate to Amazon.in\n",
    "    driver.get(\"https://www.amazon.in/\")\n",
    "    \n",
    "    try:\n",
    "        # Find the search box element\n",
    "        search_box = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "        \n",
    "        # Input the product name and press Enter\n",
    "        search_box.send_keys(product_name)\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "        \n",
    "        # Wait for the search results to load\n",
    "        driver.implicitly_wait(10)\n",
    "        \n",
    "        # Find all the product names on the page\n",
    "        product_elements = driver.find_elements_by_css_selector(\".s-result-item h2 a\")\n",
    "        \n",
    "        # Extract and print the product names\n",
    "        for product_element in product_elements:\n",
    "            print(product_element.text)\n",
    "    \n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = input(\"Enter the product to search for: \")\n",
    "    search_amazon_product(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9740eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver =  webdriver.Chrome()\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "628b117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product to search for: books\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n0   chromedriver                        0x00000001017c5638 chromedriver + 5002808\n1   chromedriver                        0x00000001017bca53 chromedriver + 4966995\n2   chromedriver                        0x000000010136da57 chromedriver + 449111\n3   chromedriver                        0x00000001013b3d05 chromedriver + 736517\n4   chromedriver                        0x00000001013b3ec1 chromedriver + 736961\n5   chromedriver                        0x00000001013f7f04 chromedriver + 1015556\n6   chromedriver                        0x00000001013da41d chromedriver + 893981\n7   chromedriver                        0x00000001013f5391 chromedriver + 1004433\n8   chromedriver                        0x00000001013da1c3 chromedriver + 893379\n9   chromedriver                        0x00000001013a5df9 chromedriver + 679417\n10  chromedriver                        0x00000001013a6fde chromedriver + 683998\n11  chromedriver                        0x00000001017822d9 chromedriver + 4727513\n12  chromedriver                        0x00000001017872de chromedriver + 4747998\n13  chromedriver                        0x00000001017452c9 chromedriver + 4477641\n14  chromedriver                        0x000000010178802d chromedriver + 4751405\n15  chromedriver                        0x000000010175b0ec chromedriver + 4567276\n16  chromedriver                        0x00000001017a57f8 chromedriver + 4872184\n17  chromedriver                        0x00000001017a59b7 chromedriver + 4872631\n18  chromedriver                        0x00000001017b5a1f chromedriver + 4938271\n19  libsystem_pthread.dylib             0x00007ff812ac04e1 _pthread_start + 125\n20  libsystem_pthread.dylib             0x00007ff812abbf6b thread_start + 15\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l_/s9krkn1s6jlgwn8tl_ywpb300000gn/T/ipykernel_82596/2320285470.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the product to search for: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0msearch_and_scrape_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/l_/s9krkn1s6jlgwn8tl_ywpb300000gn/T/ipykernel_82596/2320285470.py\u001b[0m in \u001b[0;36msearch_and_scrape_product\u001b[0;34m(product_name)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# Wait for the next page to load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mWebDriverWait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpresence_of_element_located\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"search\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# Find all the product elements on the page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/support/wait.py\u001b[0m in \u001b[0;36muntil\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0muntil_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n0   chromedriver                        0x00000001017c5638 chromedriver + 5002808\n1   chromedriver                        0x00000001017bca53 chromedriver + 4966995\n2   chromedriver                        0x000000010136da57 chromedriver + 449111\n3   chromedriver                        0x00000001013b3d05 chromedriver + 736517\n4   chromedriver                        0x00000001013b3ec1 chromedriver + 736961\n5   chromedriver                        0x00000001013f7f04 chromedriver + 1015556\n6   chromedriver                        0x00000001013da41d chromedriver + 893981\n7   chromedriver                        0x00000001013f5391 chromedriver + 1004433\n8   chromedriver                        0x00000001013da1c3 chromedriver + 893379\n9   chromedriver                        0x00000001013a5df9 chromedriver + 679417\n10  chromedriver                        0x00000001013a6fde chromedriver + 683998\n11  chromedriver                        0x00000001017822d9 chromedriver + 4727513\n12  chromedriver                        0x00000001017872de chromedriver + 4747998\n13  chromedriver                        0x00000001017452c9 chromedriver + 4477641\n14  chromedriver                        0x000000010178802d chromedriver + 4751405\n15  chromedriver                        0x000000010175b0ec chromedriver + 4567276\n16  chromedriver                        0x00000001017a57f8 chromedriver + 4872184\n17  chromedriver                        0x00000001017a59b7 chromedriver + 4872631\n18  chromedriver                        0x00000001017b5a1f chromedriver + 4938271\n19  libsystem_pthread.dylib             0x00007ff812ac04e1 _pthread_start + 125\n20  libsystem_pthread.dylib             0x00007ff812abbf6b thread_start + 15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "url = \"https://www.amazon.in/\"\n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "\n",
    "# Function to search for a product on Amazon and scrape product details\n",
    "def search_and_scrape_product(product_name):\n",
    "    # Set up the WebDriver (assuming you have ChromeDriver installed)\n",
    "    service = ChromeService(executable_path=path)\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    \n",
    "    # Navigate to Amazon.in\n",
    "    driver.get(url)\n",
    "    \n",
    "    try:\n",
    "        # Find the search box element\n",
    "        search_box = driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "        \n",
    "        # Input the product name and press Enter\n",
    "        search_box.send_keys(product_name)\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "        \n",
    "        # Wait for the search results to load\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"search\")))\n",
    "        \n",
    "        # Initialize lists to store scraped data\n",
    "        data = {\n",
    "            \"Brand Name\": [],\n",
    "            \"Name of the Product\": [],\n",
    "            \"Price\": [],\n",
    "            \"Return/Exchange\": [],\n",
    "            \"Expected Delivery\": [],\n",
    "            \"Availability\": [],\n",
    "            \"Product URL\": []\n",
    "        }\n",
    "        \n",
    "        # Loop through search result pages (up to 3 pages)\n",
    "        for page in range(1, 4):\n",
    "            if page > 1:\n",
    "                # Navigate to the next page\n",
    "                next_page = driver.find_element(By.PARTIAL_LINK_TEXT, str(page))\n",
    "                next_page.click()\n",
    "                \n",
    "                # Wait for the next page to load\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"search\")))\n",
    "            \n",
    "            # Find all the product elements on the page\n",
    "            product_elements = driver.find_elements(By.CSS_SELECTOR, \".s-result-item\")\n",
    "            \n",
    "            # Loop through products on the current page\n",
    "            for product_element in product_elements:\n",
    "                try:\n",
    "                    # Extract product details\n",
    "                    brand_name = product_element.find_element(By.CSS_SELECTOR, \".a-size-base-plus\").text\n",
    "                    product_name = product_element.find_element(By.CSS_SELECTOR, \".a-text-normal\").text\n",
    "                    price = product_element.find_element(By.CSS_SELECTOR, \".a-price .a-offscreen\").text\n",
    "                    return_exchange = product_element.find_element(By.CSS_SELECTOR, \".a-text-bold span\").text\n",
    "                    expected_delivery = product_element.find_element(By.CSS_SELECTOR, \".a-text-bold span\").text\n",
    "                    availability = product_element.find_element(By.CSS_SELECTOR, \".a-icon-alt\").text\n",
    "                    product_url = product_element.find_element(By.CSS_SELECTOR, \".a-link-normal\").get_attribute(\"href\")\n",
    "                    \n",
    "                    # Append data to lists\n",
    "                    data[\"Brand Name\"].append(brand_name)\n",
    "                    data[\"Name of the Product\"].append(product_name)\n",
    "                    data[\"Price\"].append(price)\n",
    "                    data[\"Return/Exchange\"].append(return_exchange)\n",
    "                    data[\"Expected Delivery\"].append(expected_delivery)\n",
    "                    data[\"Availability\"].append(availability)\n",
    "                    data[\"Product URL\"].append(product_url)\n",
    "                    \n",
    "                except:\n",
    "                    # If any detail is missing, replace with \"-\"\n",
    "                    data[\"Brand Name\"].append(\"-\")\n",
    "                    data[\"Name of the Product\"].append(\"-\")\n",
    "                    data[\"Price\"].append(\"-\")\n",
    "                    data[\"Return/Exchange\"].append(\"-\")\n",
    "                    data[\"Expected Delivery\"].append(\"-\")\n",
    "                    data[\"Availability\"].append(\"-\")\n",
    "                    data[\"Product URL\"].append(\"-\")\n",
    "            \n",
    "        # Create a DataFrame from the scraped data\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        df.to_csv(\"amazon_product_details.csv\", index=False)\n",
    "        \n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = input(\"Enter the product to search for: \")\n",
    "    search_and_scrape_product(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7357b7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/s9krkn1s6jlgwn8tl_ywpb300000gn/T/ipykernel_82596/4007054981.py:13: DeprecationWarning: headless property is deprecated, instead use add_argument('--headless') or add_argument('--headless=new')\n",
      "  options.headless = True\n"
     ]
    },
    {
     "ename": "NoSuchDriverException",
     "evalue": "Message: Unable to locate or obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchDriverException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l_/s9krkn1s6jlgwn8tl_ywpb300000gn/T/ipykernel_82596/4007054981.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# Scrape images for each keyword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mscrape_images_from_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/l_/s9krkn1s6jlgwn8tl_ywpb300000gn/T/ipykernel_82596/4007054981.py\u001b[0m in \u001b[0;36mscrape_images_from_google\u001b[0;34m(keyword, num_images)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Launch the browser using ChromeDriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Navigate to images.google.com\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mDesiredCapabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHROME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"browserName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;34m\"goog\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDriverFinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/common/driver_finder.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(service, options)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchDriverException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unable to locate or obtain driver for {options.capabilities['browserName']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchDriverException\u001b[0m: Message: Unable to locate or obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "\n",
    "def scrape_images_from_google(keyword, num_images):\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "\n",
    "    # Provide the path to chromedriver executable\n",
    "    service = Service('path/to/chromedriver')\n",
    "\n",
    "    # Launch the browser using ChromeDriver\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    # Navigate to images.google.com\n",
    "    driver.get(\"https://images.google.com/\")\n",
    "\n",
    "    # Find the search input field\n",
    "    search_input = driver.find_element(By.CSS_SELECTOR, \"input[name='q']\")\n",
    "\n",
    "    # Enter the keyword in the search input field and press Enter\n",
    "    search_input.send_keys(keyword)\n",
    "    search_input.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Wait for the search results to load\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Find the images\n",
    "    images = driver.find_elements(By.CSS_SELECTOR, \"img.rg_i\")\n",
    "\n",
    "    # Scrape the images\n",
    "    count = 0\n",
    "    for image in images:\n",
    "        # Open the image in a new tab\n",
    "        ActionChains(driver).move_to_element(image).key_down(Keys.CONTROL).click().key_up(Keys.CONTROL).perform()\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "\n",
    "        # Find the image source URL\n",
    "        image_url = driver.find_element(By.CSS_SELECTOR, \"img.n3VNCb\").get_attribute(\"src\")\n",
    "\n",
    "        # Save the image\n",
    "        save_image(keyword, count, image_url)\n",
    "\n",
    "        # Close the tab\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        if count == num_images:\n",
    "            break\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "def save_image(keyword, count, image_url):\n",
    "    # Create a directory to save the images if it doesn't exist\n",
    "    if not os.path.exists(keyword):\n",
    "        os.makedirs(keyword)\n",
    "\n",
    "    # Get the image name from the URL\n",
    "    image_name = image_url.split(\"/\")[-1]\n",
    "\n",
    "    # Save the image to the designated folder\n",
    "    response = requests.get(image_url)\n",
    "    with open(keyword + \"/\" + str(count + 1) + \"_\" + image_name, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "\n",
    "# Keyword and number of images to scrape\n",
    "keywords = ['fruits', 'cars', 'Machine Learning', 'Guitar', 'Cakes']\n",
    "num_images = 10\n",
    "\n",
    "# Scrape images for each keyword\n",
    "for keyword in keywords:\n",
    "    scrape_images_from_google(keyword, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23bebb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a city: india\n",
      "Coordinates not found for the given city.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_coordinates(city):\n",
    "    # URL for Google Maps search\n",
    "    url = f\"https://www.google.com/maps/search/{city}\"\n",
    "\n",
    "    # Send a GET request to retrieve the HTML content\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object to parse the HTML\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the div element containing the coordinates\n",
    "    coordinates_div = soup.find(\"div\", class_=\"ugiz4pqJLAG__primary-text gm2-body-2\")\n",
    "    \n",
    "    if coordinates_div is not None:\n",
    "        # Get the latitude and longitude from the div element\n",
    "        coordinates = coordinates_div.get_text().strip().split(\",\")\n",
    "        latitude = coordinates[0]\n",
    "        longitude = coordinates[1]\n",
    "\n",
    "        print(\"Coordinates:\")\n",
    "        print(\"Latitude:\", latitude)\n",
    "        print(\"Longitude:\", longitude)\n",
    "    else:\n",
    "        print(\"Coordinates not found for the given city.\")\n",
    "\n",
    "\n",
    "# Input the city for which you want to scrape coordinates\n",
    "city = input(\"Enter a city: \")\n",
    "\n",
    "# Scrape the coordinates for the given city\n",
    "scrape_coordinates(city)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1798ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def scrape_laptop_details():\n",
    "    # URL for the list of gaming laptops on digit.in\n",
    "    url = \"https://www.digit.in/top-products/best-gaming-laptops-40.html\"\n",
    "\n",
    "    # Send a GET request to retrieve the HTML content\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object to parse the HTML\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the div elements containing the laptop details\n",
    "    laptop_divs = soup.find_all(\"div\", class_=\"TopNumbeHeading active-campaign\")\n",
    "\n",
    "    for div in laptop_divs:\n",
    "        # Get the laptop name\n",
    "        name = div.find(\"div\", class_=\"TopNumbeHeading active-campaign\").text.strip()\n",
    "\n",
    "        # Get the laptop specifications\n",
    "        specs_div = div.find(\"div\", class_=\"Spcs-details\")\n",
    "        specifications = {}\n",
    "        for row in specs_div.find_all(\"tr\"):\n",
    "            key = row.find(\"td\", class_=\"smkey\").text.strip()\n",
    "            value = row.find(\"td\", class_=\"smvalue\").text.strip()\n",
    "            specifications[key] = value\n",
    "\n",
    "        # Print the laptop details\n",
    "        print(\"Laptop:\", name)\n",
    "        print(\"Specifications:\")\n",
    "        for key, value in specifications.items():\n",
    "            print(key + \":\", value)\n",
    "        print()\n",
    "\n",
    "\n",
    "# Scrape the laptop details\n",
    "scrape_laptop_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be229b88",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_elements_by_css_selector'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l_/s9krkn1s6jlgwn8tl_ywpb300000gn/T/ipykernel_82596/2280739135.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Execute the program to extract comments, comment upvotes, and comment post time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mextract_youtube_comments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_comments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/l_/s9krkn1s6jlgwn8tl_ywpb300000gn/T/ipykernel_82596/2280739135.py\u001b[0m in \u001b[0;36mextract_youtube_comments\u001b[0;34m(video_url, max_comments)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Scroll to load the comments dynamically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_css_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#contents #content-text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_comments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"window.scrollTo(0, document.documentElement.scrollHeight);\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait for the comments to load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_elements_by_css_selector'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "\n",
    "def extract_youtube_comments(video_url, max_comments):\n",
    "    # Set up Selenium webdriver with Chrome\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  # Run in headless mode to speed up the process\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # Open the YouTube video page\n",
    "    driver.get(video_url)\n",
    "\n",
    "    # Scroll to load the comments dynamically\n",
    "    while len(driver.find_elements_by_css_selector(\"#contents #content-text\")) < max_comments:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "        time.sleep(3)  # Wait for the comments to load\n",
    "\n",
    "    # Extract comments, comment upvotes, and comment post time\n",
    "    comments = driver.find_elements_by_css_selector(\"#contents #content-text\")\n",
    "    upvotes = driver.find_elements_by_css_selector(\"#contents #vote-count-middle\")\n",
    "    times = driver.find_elements_by_css_selector(\"#contents #header-author > yt-formatted-string > a > #text\")\n",
    "\n",
    "    # Print the extracted comments\n",
    "    for i in range(min(max_comments, len(comments))):\n",
    "        comment = comments[i].text\n",
    "        upvote = upvotes[i].text if upvotes[i].text != \"\" else \"0\"\n",
    "        post_time = times[i].get_attribute(\"aria-label\")\n",
    "        \n",
    "        print(\"Comment:\", comment)\n",
    "        print(\"Upvotes:\", upvote)\n",
    "        print(\"Posted at:\", post_time)\n",
    "        print()\n",
    "\n",
    "    # Close the Selenium webdriver\n",
    "    driver.quit()\n",
    "\n",
    "# Set the YouTube video URL and maximum number of comments to extract\n",
    "video_url = \"https://www.youtube.com/watch?v=VIDEO_ID\"\n",
    "max_comments = 500\n",
    "\n",
    "# Execute the program to extract comments, comment upvotes, and comment post time\n",
    "extract_youtube_comments(video_url, max_comments)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
